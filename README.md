#  Sentiment Analysis of Amazon Fine Food Reviews

This repository contains the code and results for the MSc Data Science Final Project titled:  
**"Sentiment Analysis of Customer Reviews Using Machine Learning"**  
Student: *Durga Prasad Gollapudi*  
University of Hertfordshire | Module: 7PAM2002  
Supervisor: *Calum Morris*

 Submitted on: 29 April 2025  
ðŸ”— GitHub: [https://github.com/DURGAPRASAD3232/sentiment-analysis-of-customers-reviews](https://github.com/DURGAPRASAD3232/sentiment-analysis-of-customers-reviews)

---

##  Overview

This project applies traditional **machine learning** and modern **deep learning** techniques to classify customer sentiments (positive/negative) based on the **Amazon Fine Food Reviews** dataset.

**Models evaluated:**
- NaÃ¯ve Bayes
- Logistic Regression
- Support Vector Machine (SVM)
- Long Short-Term Memory (LSTM)

---

##  Objectives

- Preprocess and clean customer review data.
- Implement and compare ML & DL sentiment classifiers.
- Evaluate models using **Accuracy, Precision, Recall, and F1-score**.
- Address class imbalance using **SMOTE**.
- Extract insights using visualizations and confusion matrices.
- Explore real-world applications in e-commerce.

---

##  Dataset

- Source: [Kaggle - Amazon Fine Food Reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
- Size: 568,000+ reviews
- Target: Binary sentiment classification  
  - **Positive (1)** = Score â‰¥ 4  
  - **Negative (0)** = Score â‰¤ 2  
  - **Neutral reviews (score = 3)** were removed

---

##  Methodology

###  Preprocessing
- Lowercasing, punctuation removal
- Stopword removal, lemmatization
- TF-IDF and Word2Vec embeddings
- SMOTE for class balancing

###  Models Implemented
| Type              | Model                |
|-------------------|----------------------|
| Machine Learning  | NaÃ¯ve Bayes, Logistic Regression, SVM |
| Deep Learning     | LSTM (RNN-based)     |

###  Hyperparameter Tuning
- Grid Search (ML models)
- Learning rate, batch size, early stopping (LSTM)

---

##  Evaluation Metrics

- Accuracy
- Precision
- Recall
- F1-Score
- Confusion Matrix

###  Results Summary

| Model                   | Accuracy | Precision | Recall | F1-Score |
|------------------------|----------|-----------|--------|----------|
| NaÃ¯ve Bayes            | 0.87     | 0.87      | 1.00   | 0.93     |
| Logistic Regression    | 0.88     | 0.91      | 0.88   | 0.89     |
| SVM                    | 0.91     | 0.91      | 0.91   | 0.91     |
| Logistic + SMOTE       | 0.89     | 0.91      | 0.89   | 0.90     |
| LSTM                   | 0.91     | 0.91      | 0.91   | 0.91     |

> **Conclusion**: SVM and LSTM outperformed other models in accuracy and contextual understanding.

---

## Visualizations

- Sentiment Distribution Bar Charts
- Word Clouds (Positive & Negative)
- Confusion Matrices
- Review Length Analysis
- Model Metric Comparison Charts

---

##  Key Insights

- **LSTM** shows excellent performance in capturing context and long-term dependencies.
- **SVM** is highly effective on sparse text vectors (TF-IDF).
- **SMOTE** significantly improves recall for minority class (negative reviews).
- Sentiment models can drive **real-time decision-making** in e-commerce (product feedback, brand management, customer service).

---

## Folder Structure
sentiment-analysis-of-customers-reviews/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ reviews.csv                    # Raw dataset (filtered if needed)
â”‚   â””â”€â”€ processed_reviews.csv          # Cleaned and labeled binary sentiment data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_preprocessing_eda.ipynb      # Data cleaning, EDA, word clouds
â”‚   â”œâ”€â”€ 2_ml_models.ipynb              # NaÃ¯ve Bayes, Logistic Regression, SVM
â”‚   â”œâ”€â”€ 3_lstm_model.ipynb             # LSTM implementation and evaluation
â”‚   â””â”€â”€ 4_model_comparison.ipynb       # Metric plots and comparative evaluation
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ svm_model.pkl                  # Trained SVM model
â”‚   â”œâ”€â”€ lstm_model.h5                  # Trained LSTM model
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl           # TF-IDF vectorizer for ML models
â”‚   â””â”€â”€ tokenizer.pickle               # Tokenizer used for LSTM
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix_svm.png
â”‚   â”œâ”€â”€ confusion_matrix_lstm.png
â”‚   â”œâ”€â”€ model_metrics_comparison.png
â”‚   â”œâ”€â”€ wordcloud_positive.png
â”‚   â””â”€â”€ wordcloud_negative.png
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py               # Text cleaning and tokenization functions
â”‚   â”œâ”€â”€ visualizations.py              # Word cloud, confusion matrix, charts
â”‚   â””â”€â”€ model_utils.py                 # Training, evaluation, and saving helpers
â”‚
â”œâ”€â”€ report/
â”‚   â””â”€â”€ final_project_report.pdf       # MSc Final Project Report (optional)
â”‚
â”œâ”€â”€ sentiment_.py                      # Main script to run complete pipeline
â”œâ”€â”€ README.md                          # Project overview and documentation
â”œâ”€â”€ requirements.txt                   # List of Python dependencies
â””â”€â”€ LICENSE                            # License file (MIT recommended)



